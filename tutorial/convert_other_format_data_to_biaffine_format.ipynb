{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c07455f5",
   "metadata": {},
   "source": [
    "## Demo on how to generate data from BRAT or BIO format for biaffine training\n",
    "\n",
    "- the default format of the data is below, we only read en_text, en_type, start, end indexes, you can add other information in entities after these elements for post-processing\n",
    "```\n",
    "[\n",
    "    {\"tokens\": [xx, xx, xx, ...], \n",
    "    \"entities\": [[en_text, en_type, (start_idx, end_idx)], [en_text, en_type, (start_idx, end_idx)], ...]\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```\n",
    "- note the start_idx, end_idx are token index in tokens not the absolute position in the original document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f31cb6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T03:48:48.919412Z",
     "start_time": "2022-03-02T03:48:48.885446Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff2a5d8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T03:48:48.998181Z",
     "start_time": "2022-03-02T03:48:48.991114Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# get NLPpreprocessing from https://github.com/uf-hobi-informatics-lab/NLPreprocessing\n",
    "sys.path.append(\"./NLPpreprocessing/\")\n",
    "sys.path.append(\"./NLPpreprocessing/text_process/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b407238d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T03:48:49.182133Z",
     "start_time": "2022-03-02T03:48:49.170864Z"
    }
   },
   "outputs": [],
   "source": [
    "from annotation2BIO import pre_processing, read_annotation_brat\n",
    "from annotation2BIO import logger as l1\n",
    "from sentence_tokenization import logger as l2\n",
    "l1.setLevel(logging.ERROR)\n",
    "l2.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d4d9b2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T03:48:49.358575Z",
     "start_time": "2022-03-02T03:48:49.340654Z"
    }
   },
   "outputs": [],
   "source": [
    "def json_dump(data, fn):\n",
    "    with open(fn, \"w\") as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "\n",
    "def get_sent_bound(sents):\n",
    "    sent_bound_range = dict()  # key: sent id; value: boundary range\n",
    "    for i, each in enumerate(sents):\n",
    "        try:\n",
    "            sent_start_index = each[0][1][0]\n",
    "            sent_end_index = each[-1][1][1]\n",
    "            sent_bound_range[i] = (sent_start_index, sent_end_index)\n",
    "        except Exception as ex:\n",
    "            if i != len(nsents) - 1:\n",
    "                raise RuntimeError(f'The {i}th sentence is an empty sentence')\n",
    "    return sent_bound_range\n",
    "\n",
    "\n",
    "def get_sent_idx(en, r2i, fid):\n",
    "    s, e = en[2]\n",
    "    for r in r2i:\n",
    "        ss, se = r\n",
    "        if ss <= s < e <= se:\n",
    "            return r2i[r]\n",
    "    \n",
    "    warnings.warn(f\"entity {en} in {fid} - cannot be mapped to one sentence. Will skip this entity.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_en_idx_in_sent(en, sent):\n",
    "    s, e = None, None\n",
    "    for idx, word in enumerate(sent):\n",
    "        if word[1][0] == en[2][0]:\n",
    "            s = idx\n",
    "        if word[1][1] == en[2][1]:\n",
    "            e = idx\n",
    "    if s == None:\n",
    "        for idx, word in enumerate(sent):\n",
    "            if word[1][0] < en[2][0] < word[1][1]:\n",
    "                s = idx\n",
    "                break\n",
    "    if e == None:\n",
    "        for idx, word in enumerate(sent):\n",
    "            if word[1][0] < en[2][1] < word[1][1]:\n",
    "                e = idx\n",
    "                break\n",
    "    assert s != None and e != None, f\"{en}\\n{sent}\"\n",
    "    return s, e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f37d13",
   "metadata": {},
   "source": [
    "## training data from brat to biaffine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0193158",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T03:48:50.276066Z",
     "start_time": "2022-03-02T03:48:50.272384Z"
    }
   },
   "outputs": [],
   "source": [
    "# biaffine entity format (text, type, start, end) => \n",
    "# later we need to translate the start end to indexes in sentence to construct labels and mask\n",
    "# skip BIO to overcome overlap entities issue\n",
    "# final formatted data should be json lines {sent: \"xxxx\", entity: [(en1, ty, s, e, sindex, eindex), ...]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c359b76c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T03:48:50.487208Z",
     "start_time": "2022-03-02T03:48:50.474743Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['114220', '189471', '102324']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we use 2018 n2c2 data as brat example, you can replace with any brat formatted data here\n",
    "p = Path(\"./data/2018_n2c2_ade/track2-training_data/\")\n",
    "\n",
    "fids = [fn.stem for fn in p.glob(\"*.ann\")]\n",
    "fids[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "573595ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T03:48:50.698018Z",
     "start_time": "2022-03-02T03:48:50.682540Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272, 31)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids, dev_ids = train_test_split(fids, train_size=0.9, random_state=13, shuffle=True)\n",
    "len(train_ids), len(dev_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99389b3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T03:48:51.277710Z",
     "start_time": "2022-03-02T03:48:51.264616Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def brat2biaffine_data(file_ids, file_path, test=False):\n",
    "    biaffine_data = []\n",
    "    en_track = defaultdict(list)\n",
    "\n",
    "    for fid in file_ids:\n",
    "        t_fn = file_path / f\"{fid}.txt\"\n",
    "        a_fn = file_path / f\"{fid}.ann\"\n",
    "        \n",
    "        if test:\n",
    "            ens, rels = [], []\n",
    "        else:\n",
    "            enid_map, ens, rels = read_annotation_brat(a_fn)\n",
    "\n",
    "        sents_text, sents = pre_processing(t_fn, max_len=200)\n",
    "\n",
    "        set_bound = get_sent_bound(sents)\n",
    "        range2idx = {v:k for k, v in set_bound.items()}\n",
    "\n",
    "        for en in ens:\n",
    "            sent_idx = get_sent_idx(en, range2idx, fid)\n",
    "            if not sent_idx:\n",
    "                # skip the en that cannot be mapped\n",
    "                continue\n",
    "            # get start end index in sentence; will be updated\n",
    "            sent = sents[sent_idx]\n",
    "            s_idx, e_idx = get_en_idx_in_sent(en, sent)\n",
    "            # cat reduce to only type and index for training to reduce saved data size\n",
    "            en_track[sent_idx].append([en[0], en[1], (s_idx, e_idx), en[2], sent_idx, fid])\n",
    " \n",
    "    #     for k, v in en_track.items():\n",
    "    #         biaffine_data.append({\"tokens\": [e[0] for e in sents[k]], \"entities\": v})\n",
    "    \n",
    "        # we still need to keep sentences that have no entities\n",
    "        for i in range(len(sents)):\n",
    "            biaffine_data.append(\n",
    "                {\n",
    "                    \"tokens\": [e[0] for e in sents[i]], \n",
    "                    \"entities\": sorted(en_track[i], key=lambda x: x[2][0])\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return biaffine_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14c5725a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T03:49:24.056791Z",
     "start_time": "2022-03-02T03:48:51.486160Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bg/hc9gtg592hg_wpf63cd9z7gddy1j5z/T/ipykernel_51787/803137883.py:26: UserWarning: entity ('q.4-6h. prn.', 'Frequency', (351, 363)) in 125867 - cannot be mapped to one sentence. Will skip this entity.\n",
      "  warnings.warn(f\"entity {en} in {fid} - cannot be mapped to one sentence. Will skip this entity.\")\n",
      "/var/folders/bg/hc9gtg592hg_wpf63cd9z7gddy1j5z/T/ipykernel_51787/803137883.py:26: UserWarning: entity ('cranberry ext-C-L. sporogenes [Azo Cranberry]', 'Drug', (9746, 9791)) in 112615 - cannot be mapped to one sentence. Will skip this entity.\n",
      "  warnings.warn(f\"entity {en} in {fid} - cannot be mapped to one sentence. Will skip this entity.\")\n",
      "/var/folders/bg/hc9gtg592hg_wpf63cd9z7gddy1j5z/T/ipykernel_51787/803137883.py:26: UserWarning: entity ('q.4-6h. as needed', 'Frequency', (7519, 7536)) in 113813 - cannot be mapped to one sentence. Will skip this entity.\n",
      "  warnings.warn(f\"entity {en} in {fid} - cannot be mapped to one sentence. Will skip this entity.\")\n",
      "/var/folders/bg/hc9gtg592hg_wpf63cd9z7gddy1j5z/T/ipykernel_51787/803137883.py:26: UserWarning: entity ('DAILY (Daily)', 'Frequency', (13666, 13679)) in 115157 - cannot be mapped to one sentence. Will skip this entity.\n",
      "  warnings.warn(f\"entity {en} in {fid} - cannot be mapped to one sentence. Will skip this entity.\")\n",
      "/var/folders/bg/hc9gtg592hg_wpf63cd9z7gddy1j5z/T/ipykernel_51787/803137883.py:26: UserWarning: entity ('q.4-6h. p.r.n', 'Frequency', (5300, 5313)) in 109191 - cannot be mapped to one sentence. Will skip this entity.\n",
      "  warnings.warn(f\"entity {en} in {fid} - cannot be mapped to one sentence. Will skip this entity.\")\n"
     ]
    }
   ],
   "source": [
    "biaffine_train = brat2biaffine_data(train_ids, p)\n",
    "biaffine_dev = brat2biaffine_data(dev_ids, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "418d433e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T03:49:43.374405Z",
     "start_time": "2022-03-02T03:49:24.058735Z"
    }
   },
   "outputs": [],
   "source": [
    "p_test = Path(\"/Users/alexgre/workspace/data/2018_n2c2_ade/gold_standard_test/\")\n",
    "\n",
    "test_fids = [fn.stem for fn in p_test.glob(\"*.txt\")]\n",
    "biaffine_test = brat2biaffine_data(test_fids, p_test, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "643cd6fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T03:49:43.379262Z",
     "start_time": "2022-03-02T03:49:43.375813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34930, 3831, 25766)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biaffine_train), len(biaffine_dev), len(biaffine_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6449acd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-03-01T20:38:01.694Z"
    }
   },
   "outputs": [],
   "source": [
    "json_dump(biaffine_train, \"./data/n2c2/train.json\")\n",
    "json_dump(biaffine_dev, \"./data/n2c2/dev.json\")\n",
    "json_dump(biaffine_test, \"./data/n2c2/test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5626b78d",
   "metadata": {},
   "source": [
    "## training from IOB to biaffine (no offset) (i2b2 2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a209268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T03:49:43.383425Z",
     "start_time": "2022-03-02T03:49:43.381212Z"
    }
   },
   "outputs": [],
   "source": [
    "# we use 2010 i2b2 data as BIO example, you can replace with any BIO formatted data here\n",
    "# example use conll-2003 (we have the data in ./test_data directory)\n",
    "p = Path(\"./data/2010_i2b2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63359f8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T03:49:43.393065Z",
     "start_time": "2022-03-02T03:49:43.384935Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(fn):\n",
    "    with open(fn, \"r\") as f:\n",
    "        text = f.read().strip()\n",
    "    \n",
    "    sents = text.split(\"\\n\\n\")\n",
    "    nsents = []\n",
    "    for sent in sents:\n",
    "        words = sent.strip().split(\"\\n\")\n",
    "        nsent = []\n",
    "        for i, word in enumerate(words):\n",
    "            info = word.strip().split(\" \")\n",
    "            word_text = info[0]\n",
    "            label = info[-1]\n",
    "            new_word = [word_text, label, i]\n",
    "            nsent.append(new_word)\n",
    "        nsents.append(nsent)\n",
    "    \n",
    "    return nsents\n",
    "\n",
    "\n",
    "def data2biaffine_format(data):\n",
    "    biaffine_data = []\n",
    "    \n",
    "    for sent in data:\n",
    "        tokens = []\n",
    "        entities = []\n",
    "        \n",
    "        label_ty = \"O\"\n",
    "        temp_text = []\n",
    "        idx_s = 1000\n",
    "        idx_e = 1000\n",
    "        \n",
    "        for word in sent:\n",
    "            tokens.append(word[0])\n",
    "            label = word[1]\n",
    "            if label == \"O\":\n",
    "                if label_ty != \"O\":\n",
    "                    entities.append([\" \".join(temp_text), label_ty, (idx_s, idx_e)])\n",
    "                label_ty = \"O\"\n",
    "                temp_text = []\n",
    "            elif label[0] == \"B\":\n",
    "                if label_ty != \"O\":\n",
    "                    entities.append([\" \".join(temp_text), label_ty, (idx_s, idx_e)])\n",
    "                    temp_text = []\n",
    "                label_ty = label[2:]\n",
    "                temp_text.append(word[0])\n",
    "                idx_s = word[-1]\n",
    "                idx_e = word[-1]\n",
    "            else:\n",
    "                # label if I-XX\n",
    "                if label_ty == label[2:]:\n",
    "                    idx_e = word[-1]\n",
    "                    temp_text.append(word[0])\n",
    "                else:\n",
    "                    entities.append([\" \".join(temp_text), label_ty, (idx_s, idx_e)])\n",
    "                    temp_text = [word[0]]\n",
    "                    label_ty = label[2:]\n",
    "                    idx_s = word[-1]\n",
    "                    idx_e = word[-1]\n",
    "        \n",
    "        biaffine_data.append(\n",
    "            {\n",
    "                \"tokens\": tokens,\n",
    "                \"entities\": entities\n",
    "            }\n",
    "        ) \n",
    "    \n",
    "    return biaffine_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d3514b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T03:49:44.395658Z",
     "start_time": "2022-03-02T03:49:43.394422Z"
    }
   },
   "outputs": [],
   "source": [
    "train_bio = load_data(p / \"train.txt\")\n",
    "dev_bio = load_data(p / \"dev.txt\")\n",
    "test_bio = load_data(p / \"test.txt\")\n",
    "\n",
    "i2b22010_biaffine_train = data2biaffine_format(train_bio)\n",
    "i2b22010_biaffine_dev = data2biaffine_format(dev_bio)\n",
    "i2b22010_biaffine_test = data2biaffine_format(test_bio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03b421d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T03:49:44.400450Z",
     "start_time": "2022-03-02T03:49:44.397333Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14987, 14987)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_bio), len(i2b22010_biaffine_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1d64faa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T03:49:44.407065Z",
     "start_time": "2022-03-02T03:49:44.401961Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['At', 'O', 0],\n",
       "  ['the', 'O', 1],\n",
       "  ['end', 'O', 2],\n",
       "  ['of', 'O', 3],\n",
       "  ['a', 'O', 4],\n",
       "  ['January', 'O', 5],\n",
       "  ['1967', 'O', 6],\n",
       "  ['concert', 'O', 7],\n",
       "  ['in', 'O', 8],\n",
       "  ['the', 'O', 9],\n",
       "  ['English', 'B-MISC', 10],\n",
       "  ['city', 'O', 11],\n",
       "  ['of', 'O', 12],\n",
       "  ['Nottingham', 'B-LOC', 13],\n",
       "  ['he', 'O', 14],\n",
       "  ['threw', 'O', 15],\n",
       "  ['the', 'O', 16],\n",
       "  ['sheet', 'O', 17],\n",
       "  ['of', 'O', 18],\n",
       "  ['paper', 'O', 19],\n",
       "  ['into', 'O', 20],\n",
       "  ['the', 'O', 21],\n",
       "  ['audience', 'O', 22],\n",
       "  [',', 'O', 23],\n",
       "  ['where', 'O', 24],\n",
       "  ['it', 'O', 25],\n",
       "  ['was', 'O', 26],\n",
       "  ['retrieved', 'O', 27],\n",
       "  ['by', 'O', 28],\n",
       "  ['a', 'O', 29],\n",
       "  ['fan', 'O', 30],\n",
       "  ['.', 'O', 31]],\n",
       " {'tokens': ['At',\n",
       "   'the',\n",
       "   'end',\n",
       "   'of',\n",
       "   'a',\n",
       "   'January',\n",
       "   '1967',\n",
       "   'concert',\n",
       "   'in',\n",
       "   'the',\n",
       "   'English',\n",
       "   'city',\n",
       "   'of',\n",
       "   'Nottingham',\n",
       "   'he',\n",
       "   'threw',\n",
       "   'the',\n",
       "   'sheet',\n",
       "   'of',\n",
       "   'paper',\n",
       "   'into',\n",
       "   'the',\n",
       "   'audience',\n",
       "   ',',\n",
       "   'where',\n",
       "   'it',\n",
       "   'was',\n",
       "   'retrieved',\n",
       "   'by',\n",
       "   'a',\n",
       "   'fan',\n",
       "   '.'],\n",
       "  'entities': [['English', 'MISC', (10, 10)],\n",
       "   ['Nottingham', 'LOC', (13, 13)]]})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 26\n",
    "train_bio[idx], i2b22010_biaffine_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5cf74b17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-02T03:49:44.412023Z",
     "start_time": "2022-03-02T03:49:44.408425Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[':', 'O', 0]], {'tokens': [':'], 'entities': []})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 202\n",
    "dev_bio[idx], i2b22010_biaffine_dev[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c071294",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-01T15:22:31.067585Z",
     "start_time": "2022-03-01T15:22:30.235730Z"
    }
   },
   "outputs": [],
   "source": [
    "json_dump(i2b22010_biaffine_train, \"./data/i2b22010/train.json\")\n",
    "json_dump(i2b22010_biaffine_dev, \"./data/i2b22010/dev.json\")\n",
    "json_dump(i2b22010_biaffine_test, \"./data/i2b22010/test.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
